{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_H(correspondences):\n",
    "    P = []\n",
    "    for ((x1,y1),(x2,y2)) in correspondences[:4]:\n",
    "        rows = [[x1, y1, 1, 0, 0, 0, -x1*x2, -y1*x2, -x2],\n",
    "                [0, 0, 0, x1, y1, 1, -x1*y2, -y1*y2, -y2]]\n",
    "        P.extend(rows)\n",
    "\n",
    "    _, __, V = np.linalg.svd(np.array(P))\n",
    "    H = V[-1, :] / V[-1,-1]\n",
    "    return H.reshape((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correspondences(img1, img2):\n",
    "    points = []\n",
    "    def onclick(event):\n",
    "        global correspondonces\n",
    "        # print('in event')\n",
    "        ix, iy = np.round((event.xdata, event.ydata))\n",
    "        points.append((int(ix), int(iy)))\n",
    "\n",
    "        if len(points)>=8:\n",
    "            fig.canvas.mpl_disconnect(cid)\n",
    "            correspondonces = [(p1, p2) for p1, p2 in zip(points[0::2], points[1::2])]\n",
    "    \n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img1)\n",
    "    plt.title('First view')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(img2)\n",
    "    plt.title('Second view')\n",
    "\n",
    "    cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.cvtColor(cv.imread('data/1_1.png'), cv.COLOR_BGR2RGB)\n",
    "img2 = cv.cvtColor(cv.imread('data/1_2.png'), cv.COLOR_BGR2RGB)\n",
    "\n",
    "# correspondonces = []\n",
    "# find_correspondences(img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correspondonces = [((232, 151), (111, 143)),\n",
    "#                     ((229, 83), (113, 77)),\n",
    "#                     ((148, 157), (26, 147)),\n",
    "#                     ((253, 85), (135, 81))]\n",
    "correspondonces = [((227, 80), (112, 74)),\n",
    "                    ((197, 159), (78, 150)),\n",
    "                    ((251, 82), (134, 78)),\n",
    "                    ((194, 134), (77, 125))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_cv, _ = cv.findHomography(img1_points, img2_points)\n",
    "# h_cv_inv = np.linalg.inv(h_cv)\n",
    "# h_cv, h_cv_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = find_H(correspondonces)\n",
    "h_inv = np.linalg.inv(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_points = np.array([p1 for p1,_ in correspondonces])\n",
    "img2_points = np.array([p2 for _,p2 in correspondonces])\n",
    "img2_transformed = np.array([np.matmul(h, np.array([*p1, 1])[:, np.newaxis]) for p1,_ in correspondonces])\n",
    "img2_transformed = np.array([(x/x[2])[:2] for x in img2_transformed]).squeeze()\n",
    "img1_inverse_transformed = np.array([np.matmul(h_inv, np.array([*p2, 1])[:, np.newaxis]) for _,p2 in correspondonces])\n",
    "img1_inverse_transformed = np.array([(x/x[2])[:2] for x in img1_inverse_transformed]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "s1 = 60\n",
    "s2 = 20\n",
    "\n",
    "fig = plt.figure(figsize=(25,10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img1)\n",
    "plt.scatter(img1_points[:,0], img1_points[:,1], c='blue', label='selected points', alpha=a, s=s1)\n",
    "plt.scatter(img1_inverse_transformed[:,0], img1_inverse_transformed[:,1], c='white', label='inverse transformed points', alpha=a, s=s2)\n",
    "plt.title('First view')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img2)\n",
    "plt.scatter(img2_points[:,0], img2_points[:,1], c='blue', label='selected points', alpha=a, s=s1)\n",
    "plt.scatter(img2_transformed[:,0], img2_transformed[:,1], c='white', label='transformed points', alpha=a, s=s2)\n",
    "plt.title('Second view')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary(img, H):\n",
    "    corner_points = [[0, 0, img.shape[0]-1, img.shape[0]-1], [0, img.shape[1]-1, 0, img.shape[1]-1]]\n",
    "    new_corners = [[], []]\n",
    "    for i in range(4):\n",
    "        x, y = corner_points[0][i], corner_points[1][i]\n",
    "        point = np.array([x, y, 1])[:, np.newaxis]\n",
    "        new_point = np.matmul(H, point)\n",
    "        xi, yi, _ = new_point/new_point[2]\n",
    "        new_corners[0].append(xi)\n",
    "        new_corners[1].append(yi)\n",
    "    \n",
    "    min_x, max_x = min(new_corners[0])[0], max(new_corners[0])[0]\n",
    "    min_y, max_y = min(new_corners[1])[0], max(new_corners[1])[0]\n",
    "    return (max_x, min_x), (max_y, min_y)\n",
    "\n",
    "def get_nearest_points(point, weights=False):\n",
    "    x,y = point\n",
    "    points = [(int(np.floor(x)[0]), int(np.floor(y)[0])), (int(np.floor(x)[0]), int(np.ceil(y)[0])),\n",
    "              (int(np.ceil(x)[0]), int(np.floor(y)[0])), (int(np.ceil(x)[0]), int(np.ceil(y)[0]))]\n",
    "    if weights:\n",
    "        weights = [(np.ceil(x)-x) * (np.ceil(y)-y), (np.ceil(x)-x) * (y-np.floor(y)),\n",
    "              (x-np.floor(x)) * (np.ceil(y)-y), (x-np.floor(x)) * (y-np.floor(y))]\n",
    "        return points, weights\n",
    "    else:\n",
    "        return points\n",
    "\n",
    "def interpolate(img, point):\n",
    "    intensity = 0\n",
    "    points, weights = get_nearest_points(point, weights=True)\n",
    "    for point, weight in zip(points, weights):\n",
    "        if point[0]>=0 and point[0]<img.shape[0] and point[1]>=0 and point[1]<img.shape[1]:\n",
    "            intensity += img[point]*weight\n",
    "    \n",
    "    return intensity\n",
    "\n",
    "def warp_singlechannel(img, H):\n",
    "    global offset_x, offset_y\n",
    "    (max_x, min_x), (max_y, min_y) = get_boundary(img, H)\n",
    "    l = int(np.ceil(max_x)-np.floor(min_x))\n",
    "    w = int(np.ceil(max_y)-np.floor(min_y))\n",
    "    output_shape = (l,w)\n",
    "    # print(output_shape)\n",
    "\n",
    "    if min_x<0:\n",
    "        offset_x = int(np.floor(min_x))*-1\n",
    "    else:\n",
    "        offset_x = 0\n",
    "\n",
    "    if min_y<0:\n",
    "        offset_y = int(np.floor(min_y))*-1\n",
    "    else:\n",
    "        offset_y = 0\n",
    "    \n",
    "    output = np.zeros(output_shape)\n",
    "    splatted = {}\n",
    "    # Forward warp\n",
    "    for x, row in enumerate(img): # for each row\n",
    "        for y, intensity in enumerate(row): # for each column\n",
    "            pose = np.array([x,y,1])[:, np.newaxis] # homogoenous coordinates\n",
    "            new_pose = np.matmul(H, pose) # find new coordinates\n",
    "            new_pose = new_pose/new_pose[2] # normalize\n",
    "            new_pose[0]+=offset_x\n",
    "            new_pose[1]+=offset_y\n",
    "            if (np.ceil(new_pose[0])-new_pose[0] + np.ceil(new_pose[1])-new_pose[1])==0: # if resulting coordinates are whole numbers\n",
    "                output[new_pose[:2]] = intensity # update intensity\n",
    "            else: # if not splatting is required\n",
    "                points = set(get_nearest_points(new_pose[:2])) # get four nearest points\n",
    "                for point in points: # for each point\n",
    "                    if point[0]<0 or point[0]>=l or point[1]<0 or point[1]>=w:\n",
    "                        continue\n",
    "                    try:\n",
    "                        output[point]\n",
    "                    except IndexError:\n",
    "                        print(new_pose)\n",
    "                        print(point)\n",
    "                        print()\n",
    "                    if point in splatted: # if point has been splatted before\n",
    "                        n, avg_intensity = splatted[point] # get old number of splatting contributors\n",
    "                        new_avg = (n*avg_intensity+intensity)/(n+1)\n",
    "                        splatted[point] = (n+1, new_avg) # update by adding current intensity\n",
    "                    else: # otherwise\n",
    "                        splatted[point] = (1, intensity) # avg intensity is current intensity with only 1 contributor\n",
    "\n",
    "    # Apply splatting\n",
    "    for point in splatted.keys():\n",
    "        _, avg_intensity = splatted[point]\n",
    "        output[point] = int(avg_intensity)\n",
    "\n",
    "    # # Inverse warp\n",
    "    # H_inv = np.linalg.inv(H) # calculate inverse homography\n",
    "    # to_warp = [(x,y) for x, y in zip(*np.where(output==-1))] # find points to warp. i.e. points that were not updated during forward warp\n",
    "    # for x,y in to_warp: # for each point\n",
    "    #     new_pose = np.array([x,y,1])[:, np.newaxis] # homogenous coords\n",
    "    #     pose = np.matmul(H_inv, new_pose) # apply inverse warping\n",
    "    #     pose = (pose/pose[2])\n",
    "    #     interp = interpolate(img, pose[:2]) # interpolate to find intensity\n",
    "    #     output[x,y] = int(interp)\n",
    "\n",
    "    return output\n",
    "\n",
    "def merge(r,g,b):\n",
    "    img = np.zeros(r.shape).tolist()\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            img[row][col] = [r[row,col], g[row,col], b[row,col]]\n",
    "\n",
    "    return np.array(img, dtype=np.int64)\n",
    "\n",
    "def warp_multichannel(img, H):\n",
    "    output_img = []\n",
    "    for channel in cv.split(img):\n",
    "        warped_channel = warp_singlechannel(channel, H)\n",
    "        output_img.append(warped_channel)\n",
    "        \n",
    "    return cv.merge(output_img).astype(np.int64)\n",
    "    # return merge(*output_img)\n",
    "\n",
    "def warp(img, H):\n",
    "    if len(img.shape)==3 and img.shape[0]>3:\n",
    "        return warp_multichannel(img, H)\n",
    "    else:\n",
    "        return warp_singlechannel(img, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_warped = warp_multichannel(img1, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,10))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img1_warped)\n",
    "plt.title('First view warped')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img2)\n",
    "plt.title('Second view')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_warped_adjusted = np.zeros((img2.shape[0]+offset_y, img2.shape[1]+offset_x, 3), dtype=np.int64)\n",
    "img2_t = np.zeros((img2.shape[0]+offset_y, img2.shape[1]+offset_x, 3), dtype=np.int64)\n",
    "for x in range(img2.shape[0]):\n",
    "    for y in range(img2.shape[1]):\n",
    "        img2_t[x+offset_y, y+offset_x] = img2[x,y]\n",
    "\n",
    "for x in range(img1_warped.shape[0]):\n",
    "    for y in range(img1_warped.shape[1]):\n",
    "        img1_warped_adjusted[x, y] = img1_warped[x,y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay(img1, img2):\n",
    "    op = np.zeros(img2.shape, dtype=np.int64)\n",
    "    for i in range(op.shape[0]):\n",
    "        for j in range(op.shape[1]):\n",
    "            if np.all(img1[i,j]==0):\n",
    "                op[i,j] = img2[i,j]\n",
    "            elif np.all(img2[i,j]==0):\n",
    "                op[i,j] = img1[i,j]\n",
    "            else:\n",
    "                op[i,j] = (img1[i,j]+img2[i,j])/2\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mosaic = cv.addWeighted(img1_warped_adjusted, 1, img2_t, 1, 0)\n",
    "mosaic = overlay(img1_warped_adjusted, img2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(25,10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img1_warped)\n",
    "plt.title('First view warped')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img2_t)\n",
    "plt.title('Second view')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(mosaic)\n",
    "plt.title('Mosaic')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
